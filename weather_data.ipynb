{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FC Schalke 04', 'Preußen Münster', '1.FC Saarbrücken',\n",
       "       'Hamburger SV', '1.FC Kaiserslautern', 'Hertha BSC', '1.FC Köln',\n",
       "       'Karlsruher SC', '1.FC Nürnberg', 'Meidericher SV',\n",
       "       'Borussia Dortmund', 'TSV 1860 München', 'Eintracht Braunschweig',\n",
       "       'VfB Stuttgart', 'Eintracht Frankfurt', 'SV Werder Bremen',\n",
       "       'Borussia Neunkirchen', 'Hannover 96', 'FC Bayern München',\n",
       "       'SC Tasmania 1900 Berlin (-1973)', 'Borussia Mönchengladbach',\n",
       "       'Fortuna Düsseldorf', 'Rot-Weiss Essen', 'Alemannia Aachen',\n",
       "       'MSV Duisburg', 'Kickers Offenbach', 'Rot-Weiß Oberhausen',\n",
       "       'Arminia Bielefeld', 'VfL Bochum', 'Wuppertaler SV Borussia',\n",
       "       'SC Fortuna Köln', 'Tennis Borussia Berlin', 'Bayer 05 Uerdingen',\n",
       "       'FC St. Pauli', 'SV Darmstadt 98', 'Bayer 04 Leverkusen',\n",
       "       'SV Waldhof Mannheim', 'FC 08 Homburg', 'SV Blau-Weiß Berlin',\n",
       "       'Stuttgarter Kickers', 'SG Wattenscheid 09', 'FC Hansa Rostock',\n",
       "       'SG Dynamo Dresden', 'VfB Leipzig', 'SC Freiburg',\n",
       "       'KFC Uerdingen 05', 'VfL Wolfsburg', 'SpVgg Unterhaching',\n",
       "       'SSV Ulm 1846', 'FC Energie Cottbus', '1.FSV Mainz 05',\n",
       "       'TSG 1899 Hoffenheim', 'FC Augsburg', 'SpVgg Greuther Fürth',\n",
       "       'SC Paderborn 07', 'FC Ingolstadt 04', 'RasenBallsport Leipzig',\n",
       "       '1.FC Union Berlin'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"./df_clubs_overview.pkl\")\n",
    "df['CLUB_NAME'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching clubs to their cities \n",
    "\n",
    "bundesliga_vereine_orte = {\n",
    "    'FC Schalke 04': 'Gelsenkirchen',\n",
    "    'Preußen Münster': 'Münster',\n",
    "    '1.FC Saarbrücken': 'Saarbrücken',\n",
    "    'Hamburger SV': 'Hamburg',\n",
    "    '1.FC Kaiserslautern': 'Kaiserslautern',\n",
    "    'Hertha BSC': 'Berlin',\n",
    "    '1.FC Köln': 'Köln',\n",
    "    'Karlsruher SC': 'Karlsruhe',\n",
    "    '1.FC Nürnberg': 'Nürnberg',\n",
    "    'Meidericher SV': 'Duisburg',\n",
    "    'Borussia Dortmund': 'Dortmund',\n",
    "    'TSV 1860 München': 'München',\n",
    "    'Eintracht Braunschweig': 'Braunschweig',\n",
    "    'VfB Stuttgart': 'Stuttgart',\n",
    "    'Eintracht Frankfurt': 'Frankfurt',\n",
    "    'SV Werder Bremen': 'Bremen',\n",
    "    'Borussia Neunkirchen': 'Neunkirchen',\n",
    "    'Hannover 96': 'Hannover',\n",
    "    'FC Bayern München': 'München',\n",
    "    'SC Tasmania 1900 Berlin (-1973)': 'Berlin',\n",
    "    'Borussia Mönchengladbach': 'Mönchengladbach',\n",
    "    'Fortuna Düsseldorf': 'Düsseldorf',\n",
    "    'Rot-Weiss Essen': 'Essen',\n",
    "    'Alemannia Aachen': 'Aachen',\n",
    "    'MSV Duisburg': 'Duisburg',\n",
    "    'Kickers Offenbach': 'Offenbach',\n",
    "    'Rot-Weiß Oberhausen': 'Oberhausen',\n",
    "    'Arminia Bielefeld': 'Bielefeld',\n",
    "    'VfL Bochum': 'Bochum',\n",
    "    'Wuppertaler SV Borussia': 'Wuppertal',\n",
    "    'SC Fortuna Köln': 'Köln',\n",
    "    'Tennis Borussia Berlin': 'Berlin',\n",
    "    'Bayer 05 Uerdingen': 'Krefeld',\n",
    "    'FC St. Pauli': 'Hamburg',\n",
    "    'SV Darmstadt 98': 'Darmstadt',\n",
    "    'Bayer 04 Leverkusen': 'Leverkusen',\n",
    "    'SV Waldhof Mannheim': 'Mannheim',\n",
    "    'FC 08 Homburg': 'Homburg',\n",
    "    'SV Blau-Weiß Berlin': 'Berlin',\n",
    "    'Stuttgarter Kickers': 'Stuttgart',\n",
    "    'SG Wattenscheid 09': 'Bochum',\n",
    "    'FC Hansa Rostock': 'Rostock',\n",
    "    'SG Dynamo Dresden': 'Dresden',\n",
    "    'VfB Leipzig': 'Leipzig',\n",
    "    'SC Freiburg': 'Freiburg',\n",
    "    'KFC Uerdingen 05': 'Krefeld',\n",
    "    'VfL Wolfsburg': 'Wolfsburg',\n",
    "    'SpVgg Unterhaching': 'Unterhaching',\n",
    "    'SSV Ulm 1846': 'Ulm',\n",
    "    'FC Energie Cottbus': 'Cottbus',\n",
    "    '1.FSV Mainz 05': 'Mainz',\n",
    "    'TSG 1899 Hoffenheim': 'Hoffenheim',\n",
    "    'FC Augsburg': 'Augsburg',\n",
    "    'SpVgg Greuther Fürth': 'Fürth',\n",
    "    'SC Paderborn 07': 'Paderborn',\n",
    "    'FC Ingolstadt 04': 'Ingolstadt',\n",
    "    'RasenBallsport Leipzig': 'Leipzig',\n",
    "    '1.FC Union Berlin': 'Berlin'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL of Transfermarkt Webpage\n",
    "BASE_URL = 'https://www.wetterkontor.de'\n",
    "\n",
    "# header config for Browser setup\n",
    "headers = {'User-Agent': \n",
    "           'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36'}\n",
    "\n",
    "\n",
    "def weather_url(date):\n",
    "    \"\"\"\n",
    "    Reads table \n",
    "\n",
    "    Args:\n",
    "        date (int): Accept date in form of yyyymmdd starting from 20110101\n",
    "\n",
    "    Returns:\n",
    "        response object: Provides methods and attributes to access the data returned by the HTTP request\n",
    "    \"\"\"\n",
    "    url = urljoin(BASE_URL, f'/de/wetter/deutschland/extremwerte.asp?id={date}')\n",
    "    response = requests.get(url, headers=headers)\n",
    "    print(url)\n",
    "    return response\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def split_list_into_pairs(input_list):\n",
    "    result_list = [input_list[i:i+6] for i in range(0, len(input_list), 6)]\n",
    "    return result_list\n",
    "\n",
    "\n",
    "\n",
    "def dict_to_df(col_name_ls, value_ls):\n",
    "    \"\"\"\n",
    "    Reads the column names and their values in form of lists. Store it into one dictionary to convert it to a Dataframe format \n",
    "    \n",
    "    Args:\n",
    "        col_name_ls (list['str']): list of column names\n",
    "        value_ls (list('list')): list of lists with the values for each column\n",
    "\n",
    "    Returns:\n",
    "        df (DataFrame):  \n",
    "    \"\"\"\n",
    "    dict = {}\n",
    "    for enum in range(len(col_name_ls)):\n",
    "        dict[col_name_ls[enum]] = value_ls[enum]\n",
    "    df = pd.DataFrame(dict)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_data(date, weatherstation_param):\n",
    "\n",
    "    response = weather_url(20110101)\n",
    "    soup = BeautifulSoup(response.content, 'lxml')\n",
    "    \n",
    "    # Get weather station\n",
    "    weather_stations = soup.find_all('td', class_=\"uk-text-left\")\n",
    "    weather_stations_list = [station.text.strip() for station in weather_stations]\n",
    "\n",
    "    # Get weather data as dictionary\n",
    "    weather_data = soup.find_all('td', class_=\"uk-text-center\")\n",
    "    weather_data_list = [w_data.text.strip() for w_data in weather_data]\n",
    "    weather_data_list_splitted = split_list_into_pairs(weather_data_list)\n",
    "    weather_data_list_splitted\n",
    "\n",
    "\n",
    "    keys = ['MIN_TEMP', 'MAX_TEMP', 'MIN_5_CM_NIGHT', 'SNOW_HEIGHT', 'WIND', 'RAIN']\n",
    "    weather_dict = {key: None for key in keys}\n",
    "\n",
    "    for i, key in zip(range(0,7), keys):\n",
    "        ls = []\n",
    "        for j in range(len(weather_data_list_splitted)):\n",
    "            value = weather_data_list_splitted[j][i]\n",
    "            ls.append(value)\n",
    "            \n",
    "        weather_dict[key] = ls\n",
    "\n",
    "\n",
    "    # Get sunshine duration    \n",
    "    sunshine_duration_h = soup.find_all('td', class_=\"td_beo_r\")\n",
    "    sunshine_duration_h_list = [duration.text.strip() for duration in sunshine_duration_h]\n",
    "    sunshine_duration_h_list\n",
    "\n",
    "\n",
    "    col_name_ls = ['WEATHER_STATION', 'MIN_TEMP_C', 'MAX_TEMP_C', 'MIN_5_CM_NIGHT', 'SNOW_HEIGHT_cm', 'WIND', 'RAIN_l/m2', 'SUNSHINE_DURATION_h']\n",
    "    value_ls = [weather_stations_list, weather_dict['MIN_TEMP'], weather_dict['MAX_TEMP'], weather_dict['MIN_5_CM_NIGHT'], weather_dict['SNOW_HEIGHT'], weather_dict['WIND'], weather_dict['RAIN'], sunshine_duration_h_list]\n",
    "    df = dict_to_df(col_name_ls, value_ls)\n",
    "    df = df[df['WEATHER_STATION'] == weatherstation_param]\n",
    "\n",
    "    df.drop(['MIN_5_CM_NIGHT'], axis = 1, inplace=True)\n",
    "    df.drop(['WIND'], axis = 1, inplace=True)\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.wetterkontor.de/de/wetter/deutschland/extremwerte.asp?id=20110101\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WEATHER_STATION</th>\n",
       "      <th>MIN_TEMP_C</th>\n",
       "      <th>MAX_TEMP_C</th>\n",
       "      <th>SNOW_HEIGHT_cm</th>\n",
       "      <th>RAIN_l/m2</th>\n",
       "      <th>SUNSHINE_DURATION_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Berlin/Tegel</td>\n",
       "      <td>1</td>\n",
       "      <td>3,6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0,2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WEATHER_STATION MIN_TEMP_C MAX_TEMP_C SNOW_HEIGHT_cm RAIN_l/m2  \\\n",
       "14    Berlin/Tegel          1        3,6              0         0   \n",
       "\n",
       "   SUNSHINE_DURATION_h  \n",
       "14                 0,2  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data(20220101, 'Berlin/Tegel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
