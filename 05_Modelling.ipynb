{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"./df_merge_club_transfer_data.pkl\")\n",
    "df1 = pd.read_pickle(\"./df_merge_club_transfer_data_prep1.pkl\")\n",
    "object_columns = df.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd step of data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping: {0: '1.FC Kaiserslautern', 1: '1.FC Köln', 2: '1.FC Nürnberg', 3: '1.FC Union Berlin', 4: '1.FSV Mainz 05', 5: 'Alemannia Aachen', 6: 'Arminia Bielefeld', 7: 'Bayer 04 Leverkusen', 8: 'Borussia Dortmund', 9: 'Borussia Mönchengladbach', 10: 'Eintracht Braunschweig', 11: 'Eintracht Frankfurt', 12: 'FC Augsburg', 13: 'FC Bayern München', 14: 'FC Energie Cottbus', 15: 'FC Hansa Rostock', 16: 'FC Ingolstadt 04', 17: 'FC Schalke 04', 18: 'FC St. Pauli', 19: 'Fortuna Düsseldorf', 20: 'Hamburger SV', 21: 'Hannover 96', 22: 'Hertha BSC', 23: 'Karlsruher SC', 24: 'MSV Duisburg', 25: 'RasenBallsport Leipzig', 26: 'SC Freiburg', 27: 'SC Paderborn 07', 28: 'SV Darmstadt 98', 29: 'SV Werder Bremen', 30: 'SpVgg Greuther Fürth', 31: 'TSG 1899 Hoffenheim', 32: 'VfB Stuttgart', 33: 'VfL Bochum', 34: 'VfL Wolfsburg'}\n"
     ]
    }
   ],
   "source": [
    "# Kombinieren die Werte beider Spalten in eine Serie\n",
    "combined_teams = pd.concat([df2['HOME_TEAM'], df2['AWAY_TEAM']])\n",
    "\n",
    "# Initialisieren und anpassen Sie den LabelEncoder\n",
    "le_teams = LabelEncoder()\n",
    "le_teams.fit(combined_teams)\n",
    "\n",
    "# Codieren Sie die 'HOME_TEAM' und 'AWAY_TEAM' Spalten\n",
    "df2['HOME_TEAM'] = le_teams.transform(df2['HOME_TEAM'])\n",
    "df2['AWAY_TEAM'] = le_teams.transform(df2['AWAY_TEAM'])\n",
    "\n",
    "# Erstellen ein Mapping-Dictionary für die Decodierung\n",
    "label_mapping_TEAM = {idx: label for idx, label in enumerate(le_teams.classes_)}\n",
    "\n",
    "print(\"Label Mapping:\", label_mapping_TEAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping: {0: 'Babak Rafati', 1: 'Bastian Dankert', 2: 'Benjamin Brand', 3: 'Benjamin Cortus', 4: 'Bibiana Steinhaus-Webb', 5: 'Christian Dingert', 6: 'Daniel Schlager', 7: 'Daniel Siebert', 8: 'Deniz Aytekin', 9: 'Dr. Arne Aarnink', 10: 'Dr. Felix Brych', 11: 'Dr. Franz-Xaver Wack', 12: 'Dr. Helmut Fleischer', 13: 'Dr. Jochen Drees', 14: 'Dr. Markus Merk', 15: 'Dr. Martin Thomsen', 16: 'Dr. Matthias Jöllenbeck', 17: 'Dr. Robert Kampka', 18: 'Dr. Robin Braun', 19: 'Felix Zwayer', 20: 'Florian Badstübner', 21: 'Florian Meyer', 22: 'Frank Willenborg', 23: 'Guido Winkmann', 24: 'Günter Perl', 25: 'Harm Osmers', 26: 'Herbert Fandel', 27: 'Hermann Albrecht', 28: 'Jörg Keßler', 29: 'Jürgen Jansen', 30: 'Knut Kircher', 31: 'Lutz Wagner', 32: 'Lutz-Michael Fröhlich', 33: 'Manuel Gräfe', 34: 'Marc Seemann', 35: 'Marco Fritz', 36: 'Markus Schmidt', 37: 'Markus Wingenbach', 38: 'Martin Petersen', 39: 'Michael Kempter', 40: 'Michael Weiner', 41: 'Patrick Ittrich', 42: 'Peter Gagelmann', 43: 'Peter Sippel', 44: 'Robert Hartmann', 45: 'Robert Schröder', 46: 'Sascha Stegemann', 47: 'Stefan Trautmann', 48: 'Sven Jablonski', 49: 'Sören Storks', 50: 'Thorsten Kinhöfer', 51: 'Timo Gerach', 52: 'Tobias Reichel', 53: 'Tobias Stieler', 54: 'Tobias Welz', 55: 'Uwe Kemmling', 56: 'Wolfgang Stark'}\n"
     ]
    }
   ],
   "source": [
    "le_REFEREE = LabelEncoder()\n",
    "encoded_REFEREE = le_REFEREE.fit_transform(df2['REFEREE'])\n",
    "df2['REFEREE'] = encoded_REFEREE\n",
    "\n",
    "label_mapping_REFEREE = {idx: label for idx, label in enumerate(le_REFEREE.classes_)}\n",
    "print(\"Label Mapping:\", label_mapping_REFEREE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping: {0: 'AWAY_WIN', 1: 'DRAW', 2: 'HOME_WIN'}\n"
     ]
    }
   ],
   "source": [
    "le_RESULT = LabelEncoder()\n",
    "encoded_RESULT = le_RESULT.fit_transform(df2['RESULT'])\n",
    "df2['RESULT'] = encoded_RESULT\n",
    "\n",
    "label_mapping_RESULT = {idx: label for idx, label in enumerate(le_RESULT.classes_)}\n",
    "print(\"Label Mapping:\", label_mapping_RESULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE                            datetime64[ns]\n",
      "WEEKDAY                                  int64\n",
      "MONTH                                    int64\n",
      "SEASON                                   int32\n",
      "MATCHDAY                                 int64\n",
      "HOME_TEAM                                int32\n",
      "PLACE_HOME_TEAM                          int64\n",
      "AWAY_TEAM                                int32\n",
      "PLACE_AWAY_TEAM                          int64\n",
      "WIN_PERC_HOME                          float64\n",
      "REMIS_PERC                             float64\n",
      "WIN_PERC_AWAY                          float64\n",
      "HOME_GOALS                             float64\n",
      "AWAY_GOALS                             float64\n",
      "RESULT                                   int32\n",
      "REFEREE                                  int32\n",
      "HOME_PLAYERS_COUNT                       int64\n",
      "HOME_PLAYERS_AVG_AGE                   float64\n",
      "HOME_LEGIONARIES_COUNT                   int64\n",
      "HOME_AVG_MARKET_VALUE                  float64\n",
      "HOME_TOTAL_MARKET_VALUE                float64\n",
      "HOME_AVG_AGE_JOINING                   float64\n",
      "HOME_AVG_AGE_LEAVING                   float64\n",
      "HOME_TOTAL_VALUE_JOINING_MIO           float64\n",
      "HOME_TOTAL_VALUE_LEAVING_MIO           float64\n",
      "HOME_EXPENSES_JOINING_MIO              float64\n",
      "HOME_REVENUE_LEAVING_MIO               float64\n",
      "AWAY_PLAYERS_COUNT                       int64\n",
      "AWAY_PLAYERS_AVG_AGE                   float64\n",
      "AWAY_LEGIONARIES_COUNT                   int64\n",
      "AWAY_AVG_MARKET_VALUE                  float64\n",
      "AWAY_TOTAL_MARKET_VALUE                float64\n",
      "AWAY_AVG_AGE_JOINING                   float64\n",
      "AWAY_AVG_AGE_LEAVING                   float64\n",
      "AWAY_TOTAL_VALUE_JOINING_MIO           float64\n",
      "AWAY_TOTAL_VALUE_LEAVING_MIO           float64\n",
      "AWAY_EXPENSES_JOINING_MIO              float64\n",
      "AWAY_REVENUE_LEAVING_MIO               float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df2.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOME_TEAM                             29.00\n",
      "PLACE_HOME_TEAM                        3.00\n",
      "AWAY_TEAM                             17.00\n",
      "PLACE_AWAY_TEAM                        2.00\n",
      "RESULT                                 2.00\n",
      "REFEREE                               47.00\n",
      "HOME_PLAYERS_COUNT                    29.00\n",
      "HOME_PLAYERS_AVG_AGE                  25.00\n",
      "HOME_LEGIONARIES_COUNT                14.00\n",
      "HOME_AVG_MARKET_VALUE            3400000.00\n",
      "HOME_TOTAL_MARKET_VALUE         98480000.00\n",
      "HOME_AVG_AGE_LEAVING                  26.40\n",
      "HOME_TOTAL_VALUE_JOINING_MIO            NaN\n",
      "HOME_TOTAL_VALUE_LEAVING_MIO            NaN\n",
      "HOME_EXPENSES_JOINING_MIO              9.00\n",
      "HOME_REVENUE_LEAVING_MIO               6.45\n",
      "AWAY_PLAYERS_COUNT                    33.00\n",
      "AWAY_PLAYERS_AVG_AGE                  25.60\n",
      "AWAY_LEGIONARIES_COUNT                15.00\n",
      "AWAY_AVG_MARKET_VALUE            2620000.00\n",
      "AWAY_TOTAL_MARKET_VALUE         86330000.00\n",
      "AWAY_AVG_AGE_LEAVING                  27.80\n",
      "AWAY_TOTAL_VALUE_JOINING_MIO            NaN\n",
      "AWAY_TOTAL_VALUE_LEAVING_MIO            NaN\n",
      "AWAY_EXPENSES_JOINING_MIO              4.65\n",
      "AWAY_REVENUE_LEAVING_MIO               0.05\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df2[object_columns].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE                               0\n",
      "WEEKDAY                            0\n",
      "MONTH                              0\n",
      "SEASON                             0\n",
      "MATCHDAY                           0\n",
      "HOME_TEAM                          0\n",
      "PLACE_HOME_TEAM                    0\n",
      "AWAY_TEAM                          0\n",
      "PLACE_AWAY_TEAM                    0\n",
      "WIN_PERC_HOME                   1530\n",
      "REMIS_PERC                      1530\n",
      "WIN_PERC_AWAY                   1530\n",
      "HOME_GOALS                         0\n",
      "AWAY_GOALS                         0\n",
      "RESULT                             0\n",
      "REFEREE                            0\n",
      "HOME_PLAYERS_COUNT                 0\n",
      "HOME_PLAYERS_AVG_AGE               0\n",
      "HOME_LEGIONARIES_COUNT             0\n",
      "HOME_AVG_MARKET_VALUE              0\n",
      "HOME_TOTAL_MARKET_VALUE            0\n",
      "HOME_AVG_AGE_JOINING               0\n",
      "HOME_AVG_AGE_LEAVING               0\n",
      "HOME_TOTAL_VALUE_JOINING_MIO     748\n",
      "HOME_TOTAL_VALUE_LEAVING_MIO    1224\n",
      "HOME_EXPENSES_JOINING_MIO         85\n",
      "HOME_REVENUE_LEAVING_MIO         272\n",
      "AWAY_PLAYERS_COUNT                 0\n",
      "AWAY_PLAYERS_AVG_AGE               0\n",
      "AWAY_LEGIONARIES_COUNT             0\n",
      "AWAY_AVG_MARKET_VALUE              0\n",
      "AWAY_TOTAL_MARKET_VALUE            0\n",
      "AWAY_AVG_AGE_JOINING               0\n",
      "AWAY_AVG_AGE_LEAVING               0\n",
      "AWAY_TOTAL_VALUE_JOINING_MIO     748\n",
      "AWAY_TOTAL_VALUE_LEAVING_MIO    1224\n",
      "AWAY_EXPENSES_JOINING_MIO         85\n",
      "AWAY_REVENUE_LEAVING_MIO         272\n",
      "dtype: int64\n",
      "5814\n"
     ]
    }
   ],
   "source": [
    "nan_count = df2.isna().sum()\n",
    "print(nan_count)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_pickle(\"df_merge_club_transfer_data_prep2.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "\"HOME_TEAM\", \"PLACE_HOME_TEAM\", \"HOME_PLAYERS_COUNT\", \"HOME_PLAYERS_AVG_AGE\", \"HOME_LEGIONARIES_COUNT\",\n",
    "\"HOME_AVG_MARKET_VALUE\", \"HOME_TOTAL_MARKET_VALUE\", \"HOME_AVG_AGE_JOINING\", \"HOME_AVG_AGE_LEAVING\", \n",
    "#\"HOME_TOTAL_VALUE_JOINING_MIO\",\"HOME_TOTAL_VALUE_LEAVING_MIO\",\n",
    "\"AWAY_TEAM\", \"PLACE_AWAY_TEAM\", \"AWAY_PLAYERS_COUNT\", \"AWAY_PLAYERS_AVG_AGE\", \"AWAY_LEGIONARIES_COUNT\",\n",
    "\"AWAY_AVG_MARKET_VALUE\", \"AWAY_TOTAL_MARKET_VALUE\", \"AWAY_AVG_AGE_JOINING\", \"AWAY_AVG_AGE_LEAVING\", \n",
    "#\"AWAY_TOTAL_VALUE_JOINING_MIO\", \"AWAY_TOTAL_VALUE_LEAVING_MIO\",\n",
    "\"MATCHDAY\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2[selected_features]\n",
    "y = df2['RESULT']\n",
    "# Daten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4892519346517627\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.46      0.47       349\n",
      "           1       0.25      0.09      0.13       293\n",
      "           2       0.53      0.74      0.62       521\n",
      "\n",
      "    accuracy                           0.49      1163\n",
      "   macro avg       0.42      0.43      0.40      1163\n",
      "weighted avg       0.44      0.49      0.45      1163\n",
      "\n",
      "Accuracy for class 0: 0.46\n",
      "Accuracy for class 1: 0.09\n",
      "Accuracy for class 2: 0.74\n"
     ]
    }
   ],
   "source": [
    "# Modell auswählen und trainieren\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen treffen\n",
    "y_pred = clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Genauigkeit für jede Klasse berechnen\n",
    "accuracy_per_class = np.diag(cm) / np.sum(cm, axis=1)\n",
    "\n",
    "# Modell evaluieren\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "for i, acc in enumerate(accuracy_per_class):\n",
    "    print(f\"Accuracy for class {i}: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.472055030094583\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.46      0.46       349\n",
      "           1       0.25      0.16      0.19       293\n",
      "           2       0.53      0.66      0.59       521\n",
      "\n",
      "    accuracy                           0.47      1163\n",
      "   macro avg       0.42      0.42      0.42      1163\n",
      "weighted avg       0.44      0.47      0.45      1163\n",
      "\n",
      "Accuracy for class 0: 0.46\n",
      "Accuracy for class 1: 0.16\n",
      "Accuracy for class 2: 0.66\n"
     ]
    }
   ],
   "source": [
    "# Modell auswählen und trainieren\n",
    "clf_xgb = XGBClassifier(objective='multi:softprob', random_state=42)\n",
    "clf_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen treffen\n",
    "y_pred = clf_xgb.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Genauigkeit für jede Klasse berechnen\n",
    "accuracy_per_class = np.diag(cm) / np.sum(cm, axis=1)\n",
    "\n",
    "# Modell evaluieren\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "for i, acc in enumerate(accuracy_per_class):\n",
    "    print(f\"Accuracy for class {i}: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.44969905417024936\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.52      0.45       349\n",
      "           1       0.28      0.20      0.23       293\n",
      "           2       0.56      0.55      0.55       521\n",
      "\n",
      "    accuracy                           0.45      1163\n",
      "   macro avg       0.41      0.42      0.41      1163\n",
      "weighted avg       0.44      0.45      0.44      1163\n",
      "\n",
      "Accuracy for class 0: 0.52\n",
      "Accuracy for class 1: 0.20\n",
      "Accuracy for class 2: 0.55\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# k-NN Modell erstellen\n",
    "k = 5  # Anzahl der Nachbarn\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "# Modell trainieren\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen treffen\n",
    "y_pred = knn.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Genauigkeit für jede Klasse berechnen\n",
    "accuracy_per_class = np.diag(cm) / np.sum(cm, axis=1)\n",
    "\n",
    "# Modell evaluieren\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "for i, acc in enumerate(accuracy_per_class):\n",
    "    print(f\"Accuracy for class {i}: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47893379191745483\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.56      0.50       349\n",
      "           1       0.25      0.18      0.21       293\n",
      "           2       0.60      0.59      0.60       521\n",
      "\n",
      "    accuracy                           0.48      1163\n",
      "   macro avg       0.43      0.44      0.43      1163\n",
      "weighted avg       0.47      0.48      0.47      1163\n",
      "\n",
      "Accuracy for class 0: 0.56\n",
      "Accuracy for class 1: 0.18\n",
      "Accuracy for class 2: 0.59\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "y_pred = mnb.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Genauigkeit für jede Klasse berechnen\n",
    "accuracy_per_class = np.diag(cm) / np.sum(cm, axis=1)\n",
    "\n",
    "# Modell evaluieren\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "for i, acc in enumerate(accuracy_per_class):\n",
    "    print(f\"Accuracy for class {i}: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47377472055030095\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.42      0.45       349\n",
      "           1       0.29      0.30      0.29       293\n",
      "           2       0.57      0.61      0.59       521\n",
      "\n",
      "    accuracy                           0.47      1163\n",
      "   macro avg       0.45      0.44      0.44      1163\n",
      "weighted avg       0.47      0.47      0.47      1163\n",
      "\n",
      "Accuracy for class 0: 0.42\n",
      "Accuracy for class 1: 0.30\n",
      "Accuracy for class 2: 0.61\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train, y_train)\n",
    "y_pred = qda.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Genauigkeit für jede Klasse berechnen\n",
    "accuracy_per_class = np.diag(cm) / np.sum(cm, axis=1)\n",
    "\n",
    "# Modell evaluieren\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "for i, acc in enumerate(accuracy_per_class):\n",
    "    print(f\"Accuracy for class {i}: {acc:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "darts_org",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
